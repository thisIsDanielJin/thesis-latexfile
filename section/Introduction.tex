\chapter{Introduction}
\section{Problem Statement}
The transition from IPv4 to IPv6 has shifted from a distant concern to an immediate operational challenge. With IPv4 address exhaustion and rising costs for public IPv4 addresses in cloud environments, organizations face increasing pressure to adopt IPv6. However, complete migration remains complicated by the reality that many applications and services still depend on IPv4 connectivity, whether due to legacy dependencies, third-party integrations, or hard-coded address literals.
Two primary approaches have emerged to address this challenge. Dual-Stack deployment maintains both IPv4 and IPv6 connectivity simultaneously, offering broad compatibility but requiring continued IPv4 address allocation and doubled network management overhead. Alternatively, NAT64/DNS64 with CLAT (464XLAT) enables IPv6-only infrastructure while providing translation mechanisms for IPv4 communication. This approach, proven successful in mobile networks, allows organizations to minimize their IPv4 footprint while maintaining backward compatibility.The choice between these strategies involves significant trade-offs that are not well understood in practice. Dual-Stack avoids the complexity of protocol translation but increases operational burden through duplicate network policies, routing tables, and security configurations. NAT64/DNS64/CLAT reduces IPv4 dependency but introduces translation overhead and potential bottlenecks through stateful processing. Despite the importance of this decision, operators often lack concrete performance data to guide their choice, relying instead on assumptions about latency penalties and throughput impacts that may not reflect actual deployment conditions.
This thesis addresses this gap by providing empirical performance data under controlled conditions. Rather than examining these mechanisms within complex orchestration environments where multiple variables can obscure the core performance characteristics, I focus on establishing clear baselines using standard network measurement tools. Specifically, I evaluate three widely deployed NAT64 implementations—Jool, Tayga, and Tundra—measuring both round-trip time (RTT) using ping and throughput using iperf across three distinct test environments.The experimental design deliberately prioritizes measurement precision over deployment complexity. Testing occurs across AWS cloud infrastructure, a single Ubuntu machine with namespace isolation, and a two-host Ethernet setup. This progression allows me to separate the inherent costs of translation from platform-specific effects, providing operators with fundamental performance data that can inform deployment decisions across various infrastructure contexts.
While this thesis does not include Kubernetes-specific measurements, the baseline performance characteristics it establishes are directly relevant to container orchestration decisions. Platform teams evaluating IPv6 transition strategies need to understand the basic network-layer costs before considering higher-level architectural implications. The measurements presented here provide that foundation, enabling informed decisions about when translation overhead is acceptable and which implementations offer the best performance profiles for specific use cases.


\section{Objectives and Scope}
Operators are asked to choose between Dual-Stack and NAT64/DNS64 with CLAT without a clean, reproducible baseline of translation overhead across typical environments and implementations. Many existing evaluations either remain conceptual or embed translation inside complex stacks (e.g., service meshes, autoscaling, multi-tenant clusters), which obscures the inherent cost of NAT64/CLAT itself. As a result, teams rely on informal rules of thumb about “latency penalties” or “throughput loss” that may not hold across different translators or deployment conditions.
This thesis addresses that gap by quantifying the basic network cost of NAT64/CLAT relative to a Dual-Stack baseline. It measures RTT (ping) and throughput (iperf) for three translators—Jool, Tayga, and Tundra—under three setups (AWS, single host, and two-host Ethernet) chosen to separate translation effects from surrounding platform influences. Kubernetes-scale experiments are explicitly out of scope; they are discussed theoretically to connect the baseline findings to cloud-native decision-making.
The central question is: across representative environments, what are the measurable latency and throughput implications of using NAT64/DNS64/CLAT instead of Dual-Stack, and how do they vary by translator implementation?


\section{Thesis Structure}

